{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f20778fcae",
   "metadata": {},
   "source": [
    "# Download GBIF occurrence data\n",
    "\n",
    "This notebook fetches the latest occurrence records for **Poaceae** (grasses) and\n",
    "**Cyperaceae** (sedges) from **Montserrat** via the GBIF API.\n",
    "\n",
    "**Two modes:**\n",
    "- **With GBIF credentials** (`GBIF_USER` + `GBIF_PWD`): uses the async download API\n",
    "  (no record limit, proper Darwin Core Archive)\n",
    "- **Without credentials**: falls back to the synchronous search API\n",
    "  (max 100k records, fine for small datasets)\n",
    "\n",
    "**Output files** (tab-separated, Darwin Core Archive format):\n",
    "- `data/occurrence.txt` — occurrence records\n",
    "- `data/multimedia.txt` — media records linked to occurrences"
   ]
  },
  {
   "cell_type": "code",
   "id": "7fda4343a9bb",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "import shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# GBIF credentials — optional, enables async download API\n",
    "GBIF_USER = os.environ.get(\"GBIF_USER\", \"\")\n",
    "GBIF_PWD = os.environ.get(\"GBIF_PWD\", \"\")\n",
    "\n",
    "# Country code for Montserrat\n",
    "COUNTRY = \"MS\"\n",
    "\n",
    "# Taxonomic filter: Poaceae and Cyperaceae family keys\n",
    "FAMILIES = {\n",
    "    \"Poaceae\": 3073,\n",
    "    \"Cyperaceae\": 7708,\n",
    "}\n",
    "\n",
    "# GBIF API endpoints\n",
    "GBIF_DOWNLOAD_API = \"https://api.gbif.org/v1/occurrence/download/request\"\n",
    "GBIF_SEARCH_API = \"https://api.gbif.org/v1/occurrence/search\"\n",
    "\n",
    "USE_DOWNLOAD_API = bool(GBIF_USER and GBIF_PWD)\n",
    "\n",
    "if USE_DOWNLOAD_API:\n",
    "    print(f\"GBIF credentials found (user: {GBIF_USER})\")\n",
    "    print(\"Will use the async download API.\")\n",
    "else:\n",
    "    print(\"No GBIF credentials — using synchronous search API.\")\n",
    "    print(\"(Set GBIF_USER and GBIF_PWD for the async download API.)\")\n",
    "\n",
    "print(f\"Country: {COUNTRY}\")\n",
    "print(f\"Families: {', '.join(FAMILIES.keys())}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fae7f5b830b",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# MODE A: Async download API (with credentials)\n",
    "# ============================================================\n",
    "\n",
    "if USE_DOWNLOAD_API:\n",
    "    download_request = {\n",
    "        \"creator\": GBIF_USER,\n",
    "        \"notificationAddresses\": [],\n",
    "        \"sendNotification\": False,\n",
    "        \"format\": \"DWCA\",\n",
    "        \"predicate\": {\n",
    "            \"type\": \"and\",\n",
    "            \"predicates\": [\n",
    "                {\"type\": \"equals\", \"key\": \"COUNTRY\", \"value\": COUNTRY, \"matchCase\": False},\n",
    "                {\"type\": \"equals\", \"key\": \"OCCURRENCE_STATUS\", \"value\": \"present\", \"matchCase\": False},\n",
    "                {\"type\": \"in\", \"key\": \"TAXON_KEY\", \"values\": [str(v) for v in FAMILIES.values()], \"matchCase\": False},\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"Submitting download request to GBIF...\")\n",
    "    resp = requests.post(\n",
    "        GBIF_DOWNLOAD_API, json=download_request,\n",
    "        auth=(GBIF_USER, GBIF_PWD),\n",
    "        headers={\"Content-Type\": \"application/json\"}, timeout=30,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    download_key = resp.text.strip()\n",
    "    print(f\"Download key: {download_key}\")\n",
    "    print(f\"Track at: https://www.gbif.org/occurrence/download/{download_key}\")\n",
    "    print()\n",
    "\n",
    "    # Poll until ready\n",
    "    MAX_WAIT, POLL_INTERVAL = 3600, 30\n",
    "    status_url = f\"https://api.gbif.org/v1/occurrence/download/{download_key}\"\n",
    "    start = time.time()\n",
    "    print(f\"Waiting for GBIF to prepare the download...\")\n",
    "    while True:\n",
    "        elapsed = time.time() - start\n",
    "        if elapsed > MAX_WAIT:\n",
    "            print(f\"ERROR: Timed out after {MAX_WAIT}s\")\n",
    "            sys.exit(1)\n",
    "        resp = requests.get(status_url, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        sd = resp.json()\n",
    "        status = sd.get(\"status\", \"UNKNOWN\")\n",
    "        mins, secs = int(elapsed // 60), int(elapsed % 60)\n",
    "        print(f\"  [{mins:02d}:{secs:02d}] {status}\")\n",
    "        if status == \"SUCCEEDED\":\n",
    "            download_link = sd[\"downloadLink\"]\n",
    "            print(f\"  Ready! {sd.get('totalRecords', 0):,} records, {sd.get('size', 0):,} bytes\")\n",
    "            break\n",
    "        elif status in (\"FAILED\", \"KILLED\", \"CANCELLED\"):\n",
    "            print(f\"ERROR: Download {status}\")\n",
    "            sys.exit(1)\n",
    "        time.sleep(POLL_INTERVAL)\n",
    "\n",
    "    # Download and extract\n",
    "    zip_path = \"data/gbif_download.zip\"\n",
    "    extract_dir = \"data/gbif_download\"\n",
    "    print(f\"Downloading ZIP...\")\n",
    "    resp = requests.get(download_link, stream=True, timeout=300)\n",
    "    resp.raise_for_status()\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(chunk_size=1024 * 1024):\n",
    "            f.write(chunk)\n",
    "    print(f\"  {os.path.getsize(zip_path):,} bytes\")\n",
    "\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(extract_dir)\n",
    "\n",
    "    # Copy to standard locations\n",
    "    for fname in [\"occurrence.txt\", \"multimedia.txt\"]:\n",
    "        src = os.path.join(extract_dir, fname)\n",
    "        dst = os.path.join(\"data\", fname)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy2(src, dst)\n",
    "            print(f\"  {fname}: {os.path.getsize(dst):,} bytes\")\n",
    "        elif fname == \"multimedia.txt\":\n",
    "            cols = \"gbifID\\ttype\\tformat\\tidentifier\\treferences\\ttitle\\tdescription\\tsource\\taudience\\tcreated\\tcreator\\tcontributor\\tpublisher\\tlicense\\trightsHolder\"\n",
    "            with open(dst, \"w\") as mf:\n",
    "                mf.write(cols + \"\\n\")\n",
    "            print(f\"  {fname}: created empty\")\n",
    "\n",
    "    os.remove(zip_path)\n",
    "    shutil.rmtree(extract_dir, ignore_errors=True)\n",
    "    print(\"Async download complete.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping async download — will use search API in next cell.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97664377262d",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# MODE B: Synchronous search API (no credentials needed)\n",
    "# ============================================================\n",
    "\n",
    "if not USE_DOWNLOAD_API:\n",
    "    def fetch_all_occurrences(taxon_key, country, page_size=300):\n",
    "        \"\"\"Fetch all occurrences for a taxon key in a country, handling pagination.\"\"\"\n",
    "        all_records = []\n",
    "        offset = 0\n",
    "        while True:\n",
    "            params = {\n",
    "                \"taxonKey\": taxon_key, \"country\": country,\n",
    "                \"occurrenceStatus\": \"PRESENT\", \"limit\": page_size, \"offset\": offset,\n",
    "            }\n",
    "            resp = requests.get(GBIF_SEARCH_API, params=params, timeout=30)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            results = data.get(\"results\", [])\n",
    "            all_records.extend(results)\n",
    "            if data.get(\"endOfRecords\", True) or len(results) == 0:\n",
    "                break\n",
    "            offset += page_size\n",
    "            time.sleep(0.3)\n",
    "        return all_records, data.get(\"count\", len(all_records))\n",
    "\n",
    "    all_occurrences = []\n",
    "    for family_name, taxon_key in FAMILIES.items():\n",
    "        records, total = fetch_all_occurrences(taxon_key, COUNTRY)\n",
    "        print(f\"{family_name} (key={taxon_key}): {len(records)} records (total: {total})\")\n",
    "        all_occurrences.extend(records)\n",
    "    print(f\"Total: {len(all_occurrences)} records\")\n",
    "\n",
    "    # DwC column mapping\n",
    "    OCCURRENCE_COLUMNS = [\n",
    "        \"gbifID\", \"accessRights\", \"bibliographicCitation\", \"language\", \"license\",\n",
    "        \"modified\", \"publisher\", \"references\", \"rightsHolder\", \"type\",\n",
    "        \"institutionID\", \"collectionID\", \"datasetID\", \"institutionCode\",\n",
    "        \"collectionCode\", \"datasetName\", \"ownerInstitutionCode\", \"basisOfRecord\",\n",
    "        \"informationWithheld\", \"dataGeneralizations\", \"dynamicProperties\",\n",
    "        \"occurrenceID\", \"catalogNumber\", \"recordNumber\", \"recordedBy\",\n",
    "        \"recordedByID\", \"individualCount\", \"organismQuantity\",\n",
    "        \"organismQuantityType\", \"sex\", \"lifeStage\", \"reproductiveCondition\",\n",
    "        \"caste\", \"behavior\", \"vitality\", \"establishmentMeans\",\n",
    "        \"degreeOfEstablishment\", \"pathway\", \"georeferenceVerificationStatus\",\n",
    "        \"occurrenceStatus\", \"preparations\", \"disposition\",\n",
    "        \"associatedOccurrences\", \"associatedReferences\", \"associatedSequences\",\n",
    "        \"associatedTaxa\", \"otherCatalogNumbers\", \"occurrenceRemarks\",\n",
    "        \"organismID\", \"organismName\", \"organismScope\", \"eventID\", \"parentEventID\",\n",
    "        \"fieldNumber\", \"eventDate\", \"eventTime\", \"startDayOfYear\", \"endDayOfYear\",\n",
    "        \"year\", \"month\", \"day\", \"verbatimEventDate\", \"habitat\", \"samplingProtocol\",\n",
    "        \"sampleSizeValue\", \"sampleSizeUnit\", \"samplingEffort\", \"fieldNotes\",\n",
    "        \"eventRemarks\", \"locationID\", \"continent\", \"waterBody\", \"islandGroup\",\n",
    "        \"island\", \"country\", \"countryCode\", \"stateProvince\", \"county\",\n",
    "        \"municipality\", \"locality\", \"verbatimLocality\", \"minimumElevationInMeters\",\n",
    "        \"maximumElevationInMeters\", \"verbatimElevation\",\n",
    "        \"minimumDepthInMeters\", \"maximumDepthInMeters\", \"verbatimDepth\",\n",
    "        \"minimumDistanceAboveSurfaceInMeters\", \"maximumDistanceAboveSurfaceInMeters\",\n",
    "        \"locationRemarks\", \"decimalLatitude\", \"decimalLongitude\",\n",
    "        \"geodeticDatum\", \"coordinateUncertaintyInMeters\",\n",
    "        \"coordinatePrecision\", \"pointRadiusSpatialFit\",\n",
    "        \"verbatimCoordinates\", \"verbatimLatitude\", \"verbatimLongitude\",\n",
    "        \"verbatimCoordinateSystem\", \"verbatimSRS\", \"footprintWKT\",\n",
    "        \"footprintSRS\", \"footprintSpatialFit\", \"georeferencedBy\",\n",
    "        \"georeferencedDate\", \"georeferenceProtocol\", \"georeferenceSources\",\n",
    "        \"georeferenceRemarks\", \"geologicalContextID\", \"earliestEonOrLowestEonothem\",\n",
    "        \"latestEonOrHighestEonothem\", \"earliestEraOrLowestErathem\",\n",
    "        \"latestEraOrHighestErathem\", \"earliestPeriodOrLowestSystem\",\n",
    "        \"latestPeriodOrHighestSystem\", \"earliestEpochOrLowestSeries\",\n",
    "        \"latestEpochOrHighestSeries\", \"earliestAgeOrLowestStage\",\n",
    "        \"latestAgeOrHighestStage\", \"lowestBiostratigraphicZone\",\n",
    "        \"highestBiostratigraphicZone\", \"lithostratigraphicTerms\", \"group\",\n",
    "        \"formation\", \"member\", \"bed\", \"identificationID\", \"verbatimIdentification\",\n",
    "        \"identificationQualifier\", \"typeStatus\", \"identifiedBy\", \"identifiedByID\",\n",
    "        \"dateIdentified\", \"identificationReferences\", \"identificationVerificationStatus\",\n",
    "        \"identificationRemarks\", \"taxonID\", \"scientificNameID\", \"acceptedNameUsageID\",\n",
    "        \"parentNameUsageID\", \"originalNameUsageID\", \"nameAccordingToID\",\n",
    "        \"namePublishedInID\", \"taxonConceptID\", \"scientificName\",\n",
    "        \"acceptedScientificName\", \"parentNameUsage\", \"originalNameUsage\",\n",
    "        \"nameAccordingTo\", \"namePublishedIn\", \"namePublishedInYear\",\n",
    "        \"higherClassification\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\",\n",
    "        \"subfamily\", \"genus\", \"genericName\", \"subgenus\", \"infragenericEpithet\",\n",
    "        \"specificEpithet\", \"infraspecificEpithet\", \"cultivarEpithet\", \"taxonRank\",\n",
    "        \"verbatimTaxonRank\", \"scientificNameAuthorship\", \"vernacularName\",\n",
    "        \"nomenclaturalCode\", \"taxonomicStatus\", \"nomenclaturalStatus\",\n",
    "        \"taxonRemarks\", \"datasetKey\", \"publishingCountry\", \"lastInterpreted\",\n",
    "        \"elevation\", \"elevationAccuracy\", \"depth\", \"depthAccuracy\",\n",
    "        \"distanceFromCentroidInMeters\", \"stateProvince\", \"issue\",\n",
    "        \"mediaType\", \"hasCoordinate\", \"hasGeospatialIssues\", \"taxonKey\",\n",
    "        \"acceptedTaxonKey\", \"kingdomKey\", \"phylumKey\", \"classKey\", \"orderKey\",\n",
    "        \"familyKey\", \"genusKey\", \"subgenusKey\", \"speciesKey\", \"species\",\n",
    "        \"iucnRedListCategory\", \"verbatimScientificName\",\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "    for rec in all_occurrences:\n",
    "        row = {}\n",
    "        for col in OCCURRENCE_COLUMNS:\n",
    "            val = rec.get(col, \"\")\n",
    "            if col == \"gbifID\":\n",
    "                val = rec.get(\"gbifID\", rec.get(\"key\", \"\"))\n",
    "            elif col == \"publisher\":\n",
    "                val = rec.get(\"publishingOrgKey\", \"\")\n",
    "            elif col == \"issue\":\n",
    "                issues = rec.get(\"issues\", [])\n",
    "                val = \";\".join(issues) if isinstance(issues, list) else str(issues)\n",
    "            elif col == \"mediaType\":\n",
    "                media = rec.get(\"media\", [])\n",
    "                types = list(set(m.get(\"type\", \"\") for m in media if m.get(\"type\")))\n",
    "                val = \";\".join(types)\n",
    "            elif col == \"hasCoordinate\":\n",
    "                val = str(rec.get(\"hasCoordinate\", \"\")).upper()\n",
    "            elif col == \"hasGeospatialIssues\":\n",
    "                val = str(rec.get(\"hasGeospatialIssues\", \"\")).upper()\n",
    "            elif col == \"recordedByID\":\n",
    "                ids = rec.get(\"recordedByIDs\", [])\n",
    "                val = \"|\".join(d.get(\"value\", \"\") for d in ids if isinstance(d, dict)) if isinstance(ids, list) else \"\"\n",
    "            elif col == \"identifiedByID\":\n",
    "                ids = rec.get(\"identifiedByIDs\", [])\n",
    "                val = \"|\".join(d.get(\"value\", \"\") for d in ids if isinstance(d, dict)) if isinstance(ids, list) else \"\"\n",
    "            elif isinstance(val, list):\n",
    "                val = \";\".join(str(v) for v in val)\n",
    "            elif isinstance(val, dict):\n",
    "                val = \"\"\n",
    "            if val is None:\n",
    "                val = \"\"\n",
    "            row[col] = val\n",
    "        rows.append(row)\n",
    "\n",
    "    df_occ = pd.DataFrame(rows, columns=OCCURRENCE_COLUMNS)\n",
    "    df_occ.to_csv(\"data/occurrence.txt\", sep=\"\\t\", index=False)\n",
    "    print(f\"Saved {len(df_occ)} occurrences to data/occurrence.txt\")\n",
    "\n",
    "    # Extract multimedia\n",
    "    MEDIA_COLUMNS = [\n",
    "        \"gbifID\", \"type\", \"format\", \"identifier\", \"references\",\n",
    "        \"title\", \"description\", \"source\", \"audience\", \"created\",\n",
    "        \"creator\", \"contributor\", \"publisher\", \"license\", \"rightsHolder\",\n",
    "    ]\n",
    "    media_rows = []\n",
    "    for rec in all_occurrences:\n",
    "        gbif_id = rec.get(\"gbifID\", rec.get(\"key\", \"\"))\n",
    "        for m in rec.get(\"media\", []):\n",
    "            media_rows.append({col: m.get(col, \"\") if col != \"gbifID\" else gbif_id for col in MEDIA_COLUMNS})\n",
    "    df_media = pd.DataFrame(media_rows, columns=MEDIA_COLUMNS)\n",
    "    df_media.to_csv(\"data/multimedia.txt\", sep=\"\\t\", index=False)\n",
    "    print(f\"Saved {len(df_media)} media records to data/multimedia.txt\")\n",
    "\n",
    "    print(\"Search API download complete.\")\n",
    "else:\n",
    "    print(\"Already downloaded via async API — skipping search.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35cafbbf0b5e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "df = pd.read_csv(\"data/occurrence.txt\", sep=\"\\t\", on_bad_lines=\"warn\", low_memory=False)\n",
    "print(\"=== GBIF Download Summary ===\")\n",
    "ts = pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Date: {ts}\")\n",
    "print(f\"Country: Montserrat ({COUNTRY})\")\n",
    "print(f\"Families: {', '.join(FAMILIES.keys())}\")\n",
    "mode = \"async download API\" if USE_DOWNLOAD_API else \"synchronous search API\"\n",
    "print(f\"Mode: {mode}\")\n",
    "print(f\"Total occurrences: {len(df)}\")\n",
    "n_species = df[\"species\"].nunique() if \"species\" in df.columns else 0\n",
    "print(f\"Unique species: {n_species}\")\n",
    "n_coords = df[\"decimalLatitude\"].notna().sum() if \"decimalLatitude\" in df.columns else 0\n",
    "print(f\"With coordinates: {n_coords}\")\n",
    "print()\n",
    "if \"basisOfRecord\" in df.columns:\n",
    "    print(\"Basis of record:\")\n",
    "    print(df[\"basisOfRecord\"].value_counts().to_string())\n",
    "occ_size = os.path.getsize(\"data/occurrence.txt\")\n",
    "media_size = os.path.getsize(\"data/multimedia.txt\")\n",
    "print()\n",
    "print(f\"Files: occurrence.txt ({occ_size:,} bytes), multimedia.txt ({media_size:,} bytes)\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
