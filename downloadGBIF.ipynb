{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1501ed6a2b31",
   "metadata": {},
   "source": [
    "# Download GBIF occurrence data\n",
    "\n",
    "This notebook fetches the latest occurrence records for **Poaceae** (grasses) and\n",
    "**Cyperaceae** (sedges) from **Montserrat** via the GBIF **asynchronous download API**.\n",
    "\n",
    "This uses the proper GBIF download workflow:\n",
    "1. Submit a download request (requires GBIF credentials)\n",
    "2. Poll until GBIF finishes preparing the archive\n",
    "3. Download the Darwin Core Archive ZIP\n",
    "4. Extract `occurrence.txt` and `multimedia.txt`\n",
    "\n",
    "**Credentials:** Set `GBIF_USER` and `GBIF_PWD` environment variables (or GitHub secrets).\n",
    "\n",
    "**Output files** (tab-separated, Darwin Core Archive format):\n",
    "- `data/occurrence.txt` — occurrence records\n",
    "- `data/multimedia.txt` — media records linked to occurrences"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ae4273e2009",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# GBIF credentials — required for the download API\n",
    "GBIF_USER = os.environ.get(\"GBIF_USER\", \"\")\n",
    "GBIF_PWD = os.environ.get(\"GBIF_PWD\", \"\")\n",
    "\n",
    "if not GBIF_USER or not GBIF_PWD:\n",
    "    print(\"ERROR: GBIF_USER and GBIF_PWD environment variables must be set.\")\n",
    "    print(\"Register at https://www.gbif.org/user/profile to get credentials.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Download API endpoint\n",
    "GBIF_DOWNLOAD_API = \"https://api.gbif.org/v1/occurrence/download/request\"\n",
    "\n",
    "# Country code for Montserrat\n",
    "COUNTRY = \"MS\"\n",
    "\n",
    "# Maximum time to wait for download to be ready (seconds)\n",
    "MAX_WAIT = 3600  # 1 hour\n",
    "\n",
    "# Poll interval (seconds)\n",
    "POLL_INTERVAL = 30\n",
    "\n",
    "print(f\"GBIF user: {GBIF_USER}\")\n",
    "print(f\"Country: {COUNTRY}\")\n",
    "print(\"Download API ready.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8feb37f0a16",
   "metadata": {},
   "source": [
    "# Build the download request predicate\n",
    "# Poaceae (taxonKey=3073) and Cyperaceae (taxonKey=7708) in Montserrat\n",
    "FAMILIES = {\n",
    "    \"Poaceae\": \"3073\",\n",
    "    \"Cyperaceae\": \"7708\",\n",
    "}\n",
    "\n",
    "download_request = {\n",
    "    \"creator\": GBIF_USER,\n",
    "    \"notificationAddresses\": [],\n",
    "    \"sendNotification\": False,\n",
    "    \"format\": \"DWCA\",\n",
    "    \"predicate\": {\n",
    "        \"type\": \"and\",\n",
    "        \"predicates\": [\n",
    "            {\n",
    "                \"type\": \"equals\",\n",
    "                \"key\": \"COUNTRY\",\n",
    "                \"value\": COUNTRY,\n",
    "                \"matchCase\": False\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"equals\",\n",
    "                \"key\": \"OCCURRENCE_STATUS\",\n",
    "                \"value\": \"present\",\n",
    "                \"matchCase\": False\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"in\",\n",
    "                \"key\": \"TAXON_KEY\",\n",
    "                \"values\": list(FAMILIES.values()),\n",
    "                \"matchCase\": False\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Families: {', '.join(FAMILIES.keys())}\")\n",
    "print(\"Submitting download request to GBIF...\")\n",
    "resp = requests.post(\n",
    "    GBIF_DOWNLOAD_API,\n",
    "    json=download_request,\n",
    "    auth=(GBIF_USER, GBIF_PWD),\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    timeout=30,\n",
    ")\n",
    "resp.raise_for_status()\n",
    "\n",
    "download_key = resp.text.strip()\n",
    "print(f\"Download request submitted: {download_key}\")\n",
    "print(f\"Track at: https://www.gbif.org/occurrence/download/{download_key}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e7c0e2ac16a",
   "metadata": {},
   "source": [
    "# Poll until the download is ready\n",
    "status_url = f\"https://api.gbif.org/v1/occurrence/download/{download_key}\"\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Waiting for GBIF to prepare the download (polling every {POLL_INTERVAL}s, max {MAX_WAIT}s)...\")\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    elapsed = time.time() - start_time\n",
    "    if elapsed > MAX_WAIT:\n",
    "        print(f\"ERROR: Download timed out after {MAX_WAIT}s\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    resp = requests.get(status_url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    status_data = resp.json()\n",
    "    status = status_data.get(\"status\", \"UNKNOWN\")\n",
    "    \n",
    "    minutes = int(elapsed // 60)\n",
    "    seconds = int(elapsed % 60)\n",
    "    print(f\"  [{minutes:02d}:{seconds:02d}] Status: {status}\")\n",
    "\n",
    "    if status == \"SUCCEEDED\":\n",
    "        total_records = status_data.get(\"totalRecords\", 0)\n",
    "        download_link = status_data.get(\"downloadLink\", \"\")\n",
    "        file_size = status_data.get(\"size\", 0)\n",
    "        print()\n",
    "        print(f\"Download ready!\")\n",
    "        print(f\"  Records: {total_records:,}\")\n",
    "        print(f\"  Size: {file_size:,} bytes\")\n",
    "        print(f\"  Link: {download_link}\")\n",
    "        break\n",
    "    elif status in (\"FAILED\", \"KILLED\", \"CANCELLED\"):\n",
    "        print(f\"ERROR: Download {status}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    time.sleep(POLL_INTERVAL)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "121be72e341e",
   "metadata": {},
   "source": [
    "# Download the ZIP file\n",
    "zip_path = \"data/gbif_download.zip\"\n",
    "extract_dir = \"data/gbif_download\"\n",
    "\n",
    "print(f\"Downloading {download_link} ...\")\n",
    "resp = requests.get(download_link, stream=True, timeout=300)\n",
    "resp.raise_for_status()\n",
    "\n",
    "total_size = int(resp.headers.get(\"content-length\", 0))\n",
    "downloaded = 0\n",
    "\n",
    "with open(zip_path, \"wb\") as f:\n",
    "    for chunk in resp.iter_content(chunk_size=1024 * 1024):  # 1MB chunks\n",
    "        f.write(chunk)\n",
    "        downloaded += len(chunk)\n",
    "        if total_size > 0:\n",
    "            pct = downloaded * 100 // total_size\n",
    "            print(f\"  Downloaded {downloaded:,} / {total_size:,} bytes ({pct}%)\", end=\"\\r\")\n",
    "\n",
    "actual_size = os.path.getsize(zip_path)\n",
    "print(f\"  Downloaded {actual_size:,} bytes to {zip_path}\")\n",
    "print()\n",
    "\n",
    "# Extract the ZIP\n",
    "print(f\"Extracting to {extract_dir}/ ...\")\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "    members = zf.namelist()\n",
    "    print(f\"  Archive contains {len(members)} files:\")\n",
    "    for m in members:\n",
    "        info = zf.getinfo(m)\n",
    "        print(f\"    {m} ({info.file_size:,} bytes)\")\n",
    "    zf.extractall(extract_dir)\n",
    "\n",
    "print(\"Extraction complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8070e05ac92a",
   "metadata": {},
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Find occurrence.txt and multimedia.txt in the extracted archive\n",
    "occ_src = os.path.join(extract_dir, \"occurrence.txt\")\n",
    "media_src = os.path.join(extract_dir, \"multimedia.txt\")\n",
    "\n",
    "occ_dst = \"data/occurrence.txt\"\n",
    "media_dst = \"data/multimedia.txt\"\n",
    "\n",
    "if os.path.exists(occ_src):\n",
    "    shutil.copy2(occ_src, occ_dst)\n",
    "    occ_size = os.path.getsize(occ_dst)\n",
    "    print(f\"Copied occurrence.txt ({occ_size:,} bytes)\")\n",
    "else:\n",
    "    print(f\"WARNING: {occ_src} not found in archive!\")\n",
    "    # List what IS in the archive\n",
    "    for f in glob.glob(os.path.join(extract_dir, \"*\")):\n",
    "        print(f\"  Found: {os.path.basename(f)}\")\n",
    "\n",
    "if os.path.exists(media_src):\n",
    "    shutil.copy2(media_src, media_dst)\n",
    "    media_size = os.path.getsize(media_dst)\n",
    "    print(f\"Copied multimedia.txt ({media_size:,} bytes)\")\n",
    "else:\n",
    "    # Create an empty multimedia.txt if not present\n",
    "    with open(media_dst, \"w\") as f:\n",
    "        f.write(\"gbifID\\ttype\\tformat\\tidentifier\\treferences\\ttitle\\tdescription\\tsource\\taudience\\tcreated\\tcreator\\tcontributor\\tpublisher\\tlicense\\trightsHolder\\n\")\n",
    "    print(\"No multimedia.txt in archive — created empty file.\")\n",
    "\n",
    "# Quick summary\n",
    "import pandas as pd\n",
    "\n",
    "print()\n",
    "print(\"=== GBIF Download Summary ===\")\n",
    "print(f\"Download key: {download_key}\")\n",
    "print(f\"Country: Montserrat ({COUNTRY})\")\n",
    "print(f\"Scope: Poaceae + Cyperaceae\")\n",
    "\n",
    "df = pd.read_csv(occ_dst, sep=\"\\t\", on_bad_lines=\"warn\", low_memory=False)\n",
    "print(f\"Total occurrences: {len(df)}\")\n",
    "\n",
    "n_species = df[\"species\"].nunique() if \"species\" in df.columns else 0\n",
    "print(f\"Unique species: {n_species}\")\n",
    "\n",
    "n_coords = df[\"decimalLatitude\"].notna().sum() if \"decimalLatitude\" in df.columns else 0\n",
    "print(f\"With coordinates: {n_coords}\")\n",
    "\n",
    "if \"kingdom\" in df.columns:\n",
    "    print()\n",
    "    print(\"Kingdom breakdown:\")\n",
    "    for k, c in df[\"kingdom\"].value_counts().items():\n",
    "        print(f\"  {k}: {c} records\")\n",
    "\n",
    "# Clean up ZIP (keep extracted dir for reference)\n",
    "os.remove(zip_path)\n",
    "print()\n",
    "print(f\"Cleaned up {zip_path}\")\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
