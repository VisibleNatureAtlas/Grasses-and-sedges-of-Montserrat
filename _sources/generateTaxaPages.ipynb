{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate taxa pages with OSM maps\n",
    "\n",
    "This notebook generates enriched species pages for the Visible Nature Atlas.\n",
    "For each species, it:\n",
    "1. Fetches worldwide GBIF occurrence records (with coordinates)\n",
    "2. Generates an interactive Leaflet/OpenStreetMap map\n",
    "3. Fetches a Wikipedia introduction\n",
    "4. Writes a complete markdown page with embedded map HTML\n",
    "\n",
    "**Prerequisites**: Run `inspectData.ipynb` first to generate `gbifMontserrat.ttl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import folium\n",
    "import yaml\n",
    "import tqdm\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import RDFS\n",
    "\n",
    "WDT = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "WD  = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "\n",
    "os.makedirs('taxa', exist_ok=True)\n",
    "os.makedirs('maps', exist_ok=True)\n",
    "\n",
    "print('Dependencies loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the local RDF graph\n",
    "\n",
    "We load `gbifMontserrat.ttl` generated by `inspectData.ipynb` to get the list of species and their Wikidata URIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "g.parse('gbifMontserrat.ttl', format='turtle')\n",
    "\n",
    "# Extract distinct taxa: {taxon_label: wikidata_qid}\n",
    "taxa_query = \"\"\"\n",
    "PREFIX wd:  <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?taxon ?taxonLabel WHERE {\n",
    "    ?obs wdt:P225 ?taxon .\n",
    "    ?taxon rdfs:label ?taxonLabel .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "taxa = {}\n",
    "for row in g.query(taxa_query):\n",
    "    qid = str(row.taxon).replace('http://www.wikidata.org/entity/', '')\n",
    "    label = str(row.taxonLabel)\n",
    "    taxa[label] = {'qid': qid, 'uri': str(row.taxon)}\n",
    "\n",
    "print(f'Found {len(taxa)} distinct taxa:')\n",
    "for name, info in sorted(taxa.items()):\n",
    "    print(f'  {name} ({info[\"qid\"]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: fetch worldwide occurrences from GBIF API\n",
    "\n",
    "We query the GBIF occurrence API to get georeferenced worldwide records for each species. \n",
    "This gives us coordinates to plot on a global OSM map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_gbif_occurrences(taxon_name, limit=300):\n",
    "    \"\"\"Fetch georeferenced GBIF occurrences for a species by name.\n",
    "    Returns a list of dicts with lat, lon, country, year, institutionCode.\n",
    "    \"\"\"\n",
    "    url = 'https://api.gbif.org/v1/occurrence/search'\n",
    "    params = {\n",
    "        'scientificName': taxon_name,\n",
    "        'hasCoordinate': 'true',\n",
    "        'hasGeospatialIssue': 'false',\n",
    "        'limit': limit,\n",
    "        'offset': 0\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, timeout=20)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        results = []\n",
    "        for rec in data.get('results', []):\n",
    "            lat = rec.get('decimalLatitude')\n",
    "            lon = rec.get('decimalLongitude')\n",
    "            if lat is not None and lon is not None:\n",
    "                results.append({\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'country': rec.get('country', ''),\n",
    "                    'year': rec.get('year', ''),\n",
    "                    'institution': rec.get('institutionCode', ''),\n",
    "                    'gbifID': rec.get('gbifID', ''),\n",
    "                    'basisOfRecord': rec.get('basisOfRecord', '')\n",
    "                })\n",
    "        return results, data.get('count', 0)\n",
    "    except Exception as e:\n",
    "        print(f'  Warning: could not fetch GBIF occurrences for {taxon_name}: {e}')\n",
    "        return [], 0\n",
    "\n",
    "\n",
    "def get_wikipedia_intro(taxon_name):\n",
    "    \"\"\"Fetch the introductory paragraph from English Wikipedia.\"\"\"\n",
    "    url = 'https://en.wikipedia.org/w/api.php'\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': taxon_name.replace(' ', '_'),\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "        'redirects': 1\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, timeout=10)\n",
    "        data = resp.json()\n",
    "        page = next(iter(data['query']['pages'].values()))\n",
    "        extract = page.get('extract', '').strip()\n",
    "        # Return only the first paragraph (up to first double newline)\n",
    "        paragraphs = [p.strip() for p in extract.split('\\n') if p.strip()]\n",
    "        return paragraphs[0] if paragraphs else ''\n",
    "    except Exception as e:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def resolve_license_label(license_uri):\n",
    "    \"\"\"Convert a Wikidata license URI to a (label, url) tuple.\"\"\"\n",
    "    license_map = {\n",
    "        'Q18199165': ('CC BY 4.0',       'https://creativecommons.org/licenses/by/4.0/'),\n",
    "        'Q20007257': ('CC BY-SA 4.0',    'https://creativecommons.org/licenses/by-sa/4.0/'),\n",
    "        'Q6938433':  ('CC0 1.0',         'https://creativecommons.org/publicdomain/zero/1.0/'),\n",
    "        'Q19068220': ('CC BY-NC 4.0',    'https://creativecommons.org/licenses/by-nc/4.0/'),\n",
    "        'Q26952697': ('CC BY-NC-SA 4.0', 'https://creativecommons.org/licenses/by-nc-sa/4.0/'),\n",
    "        'Q35254':    ('CC BY-SA 3.0',    'https://creativecommons.org/licenses/by-sa/3.0/'),\n",
    "        'Q24082749': ('CC BY-SA 4.0',    'https://creativecommons.org/licenses/by-sa/4.0/'),\n",
    "    }\n",
    "    s = str(license_uri)\n",
    "    if 'wikidata.org/entity/Q' in s:\n",
    "        qid = s.split('/')[-1]\n",
    "        if qid in license_map:\n",
    "            return license_map[qid]\n",
    "        return qid, s\n",
    "    s_lower = s.lower()\n",
    "    if 'publicdomain/zero' in s_lower:   return 'CC0 1.0', s\n",
    "    if 'by-nc-sa' in s_lower:           return 'CC BY-NC-SA 4.0', s\n",
    "    if 'by-nc' in s_lower:              return 'CC BY-NC 4.0', s\n",
    "    if 'by-sa' in s_lower:              return 'CC BY-SA 4.0', s\n",
    "    if 'by' in s_lower:                 return 'CC BY 4.0', s\n",
    "    return s, s\n",
    "\n",
    "\n",
    "print('Helper functions defined.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Folium map for a species\n",
    "\n",
    "Creates an interactive OpenStreetMap map with clustered observation markers.\n",
    "Returns the path to the saved HTML file (embedded in the markdown page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_species_map(taxon_name, occurrences, output_path):\n",
    "    \"\"\"Generate a Folium map with observation points and save as HTML.\n",
    "    \n",
    "    Args:\n",
    "        taxon_name: Scientific name of the species\n",
    "        occurrences: List of occurrence dicts with lat, lon, country, year, institution, gbifID\n",
    "        output_path: Path to save the HTML map file\n",
    "    Returns:\n",
    "        Path to the saved HTML file, or None if no occurrences\n",
    "    \"\"\"\n",
    "    if not occurrences:\n",
    "        return None\n",
    "\n",
    "    # Compute centroid for initial map view\n",
    "    lats = [o['lat'] for o in occurrences]\n",
    "    lons = [o['lon'] for o in occurrences]\n",
    "    center = [sum(lats) / len(lats), sum(lons) / len(lons)]\n",
    "\n",
    "    m = folium.Map(\n",
    "        location=center,\n",
    "        zoom_start=3,\n",
    "        tiles='OpenStreetMap',\n",
    "        width='100%',\n",
    "        height='450px'\n",
    "    )\n",
    "\n",
    "    # Add tile layer attribution\n",
    "    folium.TileLayer(\n",
    "        tiles='https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',\n",
    "        attr='© <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors',\n",
    "        name='OpenStreetMap',\n",
    "        overlay=False,\n",
    "        control=True\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Colour-code by basis of record\n",
    "    color_map = {\n",
    "        'HUMAN_OBSERVATION': '#2ecc71',\n",
    "        'PRESERVED_SPECIMEN': '#e67e22',\n",
    "        'MACHINE_OBSERVATION': '#3498db',\n",
    "        'LITERATURE': '#9b59b6',\n",
    "        'MATERIAL_SAMPLE': '#e74c3c',\n",
    "    }\n",
    "\n",
    "    for occ in occurrences:\n",
    "        color = color_map.get(occ.get('basisOfRecord', ''), '#95a5a6')\n",
    "        year_str = f\", {occ['year']}\" if occ.get('year') else ''\n",
    "        inst_str = f\"<br><em>{occ['institution']}</em>\" if occ.get('institution') else ''\n",
    "        gbif_link = ''\n",
    "        if occ.get('gbifID'):\n",
    "            gbif_link = f'<br><a href=\"https://www.gbif.org/occurrence/{occ[\"gbifID\"]}\" target=\"_blank\">GBIF record</a>'\n",
    "        \n",
    "        popup_html = (\n",
    "            f\"<b>{taxon_name}</b><br>\"\n",
    "            f\"{occ.get('country', '')}{year_str}\"\n",
    "            f\"{inst_str}\"\n",
    "            f\"{gbif_link}\"\n",
    "        )\n",
    "        folium.CircleMarker(\n",
    "            location=[occ['lat'], occ['lon']],\n",
    "            radius=5,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7,\n",
    "            popup=folium.Popup(popup_html, max_width=250),\n",
    "            tooltip=f\"{occ.get('country', '')} {year_str}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Legend\n",
    "    legend_html = '''\n",
    "    <div style=\"position:fixed; bottom:20px; left:20px; z-index:9999;\n",
    "                background:white; padding:10px; border-radius:6px;\n",
    "                border:1px solid #ccc; font-size:12px; line-height:1.8;\">\n",
    "        <b>Basis of record</b><br>\n",
    "        <span style=\"color:#2ecc71;\">●</span> Human observation<br>\n",
    "        <span style=\"color:#e67e22;\">●</span> Preserved specimen<br>\n",
    "        <span style=\"color:#3498db;\">●</span> Machine observation<br>\n",
    "        <span style=\"color:#9b59b6;\">●</span> Literature<br>\n",
    "        <span style=\"color:#95a5a6;\">●</span> Other\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    m.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "print('Map generation function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load taxa information from the existing pipeline\n",
    "\n",
    "We extract taxonpages data from the GBIF RDF graph to get observations grouped by publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the local RDF graph for all observation data\n",
    "obs_query = \"\"\"\n",
    "PREFIX wd:  <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dc:   <http://purl.org/dc/elements/1.1/>\n",
    "\n",
    "SELECT DISTINCT ?taxon ?taxonLabel ?publisher ?publisherLabel \n",
    "                ?observation ?gbifObservation ?media_url ?license WHERE {\n",
    "    ?media wdt:P2699 ?media_url ;\n",
    "           wdt:P275 ?license ;\n",
    "           wdt:P361 ?observation .\n",
    "    ?observation wdt:P225 ?taxon ;\n",
    "                 wdt:P854 ?gbifObservation ;\n",
    "                 wdt:P123 ?publisher .\n",
    "    ?taxon rdfs:label ?taxonLabel .\n",
    "    ?publisher rdfs:label ?publisherLabel .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Build taxonpages: {taxon_label: {qid, publisher: {org: [{obs_id, media, license}]}}}\n",
    "taxonpages = {}\n",
    "\n",
    "for row in g.query(obs_query):\n",
    "    taxon_label = str(row.taxonLabel)\n",
    "    qid = str(row.taxon).replace('http://www.wikidata.org/entity/', '')\n",
    "    publisher = str(row.publisherLabel)\n",
    "    obs_id = str(row.gbifObservation)\n",
    "    media_url = str(row.media_url)\n",
    "    license_uri = str(row.license)\n",
    "\n",
    "    if taxon_label not in taxonpages:\n",
    "        taxonpages[taxon_label] = {'qid': qid, 'uri': str(row.taxon), 'publishers': {}}\n",
    "    \n",
    "    if publisher not in taxonpages[taxon_label]['publishers']:\n",
    "        taxonpages[taxon_label]['publishers'][publisher] = {}\n",
    "    \n",
    "    if obs_id not in taxonpages[taxon_label]['publishers'][publisher]:\n",
    "        taxonpages[taxon_label]['publishers'][publisher][obs_id] = {\n",
    "            'obs_id': obs_id,\n",
    "            'media': [],\n",
    "            'license': license_uri\n",
    "        }\n",
    "    \n",
    "    if media_url and media_url != 'nan':\n",
    "        existing = taxonpages[taxon_label]['publishers'][publisher][obs_id]['media']\n",
    "        if media_url not in existing:\n",
    "            existing.append(media_url)\n",
    "\n",
    "print(f'Loaded {len(taxonpages)} taxa with observation data.')\n",
    "for name in sorted(taxonpages.keys()):\n",
    "    n_obs = sum(len(obs) for obs in taxonpages[name]['publishers'].values())\n",
    "    print(f'  {name}: {len(taxonpages[name][\"publishers\"])} publishers, {n_obs} observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate enriched taxa pages\n",
    "\n",
    "For each species we:\n",
    "1. Fetch worldwide GBIF occurrences (for the map)\n",
    "2. Fetch the Wikipedia introduction\n",
    "3. Generate a Folium/OSM map saved as `maps/<Species_name>.html`\n",
    "4. Write a complete markdown page that embeds the map via an `<iframe>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_taxa = []\n",
    "\n",
    "for taxon_name in tqdm.tqdm(sorted(taxonpages.keys()), desc='Generating taxa pages'):\n",
    "    info = taxonpages[taxon_name]\n",
    "    qid = info['qid']\n",
    "    \n",
    "    # --- 1. Wikipedia introduction ---\n",
    "    wiki_intro = get_wikipedia_intro(taxon_name)\n",
    "    time.sleep(0.5)  # be polite to the API\n",
    "\n",
    "    # --- 2. Worldwide GBIF occurrences for the map ---\n",
    "    occurrences, total_count = fetch_gbif_occurrences(taxon_name, limit=300)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # --- 3. Generate map ---\n",
    "    safe_name = taxon_name.replace(' ', '_')\n",
    "    map_path = f'maps/{safe_name}.html'\n",
    "    generate_species_map(taxon_name, occurrences, map_path)\n",
    "\n",
    "    # --- 4. Write markdown page ---\n",
    "    page_path = f'taxa/{safe_name}.md'\n",
    "    toc_taxa.append({'file': f'taxa/{safe_name}'})\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    # Title\n",
    "    lines.append(f'# *{taxon_name}*')\n",
    "    lines.append('')\n",
    "\n",
    "    # Wikidata / Scholia link\n",
    "    lines.append(\n",
    "        f'[Wikidata ({qid})](https://www.wikidata.org/wiki/{qid}) · '\n",
    "        f'[Scholia](https://scholia.toolforge.org/taxon/{qid}) · '\n",
    "        f'[GBIF species page](https://www.gbif.org/species/search?q={taxon_name.replace(\" \", \"%20\")})'\n",
    "    )\n",
    "    lines.append('')\n",
    "\n",
    "    # Wikipedia introduction\n",
    "    if wiki_intro:\n",
    "        lines.append('## About this species')\n",
    "        lines.append('')\n",
    "        lines.append(wiki_intro)\n",
    "        lines.append('')\n",
    "        wp_url = f'https://en.wikipedia.org/wiki/{taxon_name.replace(\" \", \"_\")}'\n",
    "        lines.append(f'Read more on [English Wikipedia]({wp_url}).')\n",
    "        lines.append('')\n",
    "\n",
    "    # Map section\n",
    "    lines.append('## Global distribution')\n",
    "    lines.append('')\n",
    "    if occurrences:\n",
    "        lines.append(\n",
    "            f'Map shows **{len(occurrences)}** georeferenced GBIF records '\n",
    "            f'(out of {total_count} total) for *{taxon_name}* worldwide. '\n",
    "            f'Click markers for details.'\n",
    "        )\n",
    "        lines.append('')\n",
    "        # Embed the map as a raw HTML iframe\n",
    "        # The path is relative to the taxa/ directory, so we go up one level\n",
    "        lines.append('```{raw} html')\n",
    "        lines.append(f'<iframe src=\"../{map_path}\" width=\"100%\" height=\"500px\" '\n",
    "                     f'frameborder=\"0\" scrolling=\"no\" '\n",
    "                     f'style=\"border-radius:8px; margin-bottom:1rem;\"></iframe>')\n",
    "        lines.append('```')\n",
    "        lines.append('')\n",
    "        lines.append(\n",
    "            f'Map data © [OpenStreetMap](https://www.openstreetmap.org/copyright) contributors. '\n",
    "            f'Occurrence data from [GBIF](https://www.gbif.org/).'\n",
    "        )\n",
    "    else:\n",
    "        lines.append('*No georeferenced occurrence records found in GBIF for this species.*')\n",
    "    lines.append('')\n",
    "\n",
    "    # Observations from Montserrat\n",
    "    lines.append('## Observations from Montserrat')\n",
    "    lines.append('')\n",
    "    lines.append('The following observations are from the GBIF dataset covering Montserrat grasses and sedges.')\n",
    "    lines.append('')\n",
    "\n",
    "    for org_name, obs_dict in sorted(info['publishers'].items()):\n",
    "        lines.append(f'### {org_name}')\n",
    "        lines.append('')\n",
    "        for obs_id, obs_data in obs_dict.items():\n",
    "            license_label, license_url = resolve_license_label(obs_data['license'])\n",
    "            lines.append(f'**Observation:** [{obs_id}]({obs_id})  ')\n",
    "            lines.append(f'**License:** [{license_label}]({license_url})')\n",
    "            lines.append('')\n",
    "            for media_url in obs_data['media']:\n",
    "                if media_url and media_url != 'nan':\n",
    "                    # Prefer medium-sized images over square thumbnails\n",
    "                    display_url = media_url.replace('square', 'medium')\n",
    "                    lines.append(f'![{taxon_name} — {org_name}]({display_url})')\n",
    "                    lines.append('')\n",
    "\n",
    "    # Write the file\n",
    "    with open(page_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(lines))\n",
    "\n",
    "print(f'\\nGenerated {len(toc_taxa)} taxa pages.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update `_toc.yml`\n",
    "\n",
    "Update the table of contents with the newly generated pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Montserrat overview map\n",
    "\n",
    "Build a single map of all georeferenced GBIF observations on Montserrat,\n",
    "coloured by species. Saved as `maps/montserrat_overview.html` and embedded in `intro.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import colorsys\n",
    "\n",
    "# Load the raw GBIF occurrence data (Montserrat dataset)\n",
    "df_occ = pd.read_csv(\n",
    "    'data/0002020-240626123714530/occurrence.txt',\n",
    "    sep='\\t', on_bad_lines='warn', low_memory=False\n",
    ")\n",
    "\n",
    "# Keep only georeferenced species-level records\n",
    "df_coords = df_occ[\n",
    "    df_occ['decimalLatitude'].notna() &\n",
    "    df_occ['decimalLongitude'].notna() &\n",
    "    (df_occ['taxonRank'] == 'SPECIES')\n",
    "].copy()\n",
    "\n",
    "print(f'Georeferenced records: {len(df_coords)} across {df_coords[\"species\"].nunique()} species')\n",
    "\n",
    "# Assign a distinct colour per species using evenly spaced hues\n",
    "species_list = sorted(df_coords['species'].dropna().unique())\n",
    "n = len(species_list)\n",
    "\n",
    "def hsl_to_hex(h, s, l):\n",
    "    r, g, b = colorsys.hls_to_rgb(h, l, s)\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(r*255), int(g*255), int(b*255))\n",
    "\n",
    "species_colours = {\n",
    "    sp: hsl_to_hex(i / n, 0.75, 0.42)\n",
    "    for i, sp in enumerate(species_list)\n",
    "}\n",
    "\n",
    "# Build the overview map centred on Montserrat\n",
    "overview_map = folium.Map(\n",
    "    location=[16.745, -62.202],\n",
    "    zoom_start=12,\n",
    "    tiles='OpenStreetMap',\n",
    "    width='100%',\n",
    "    height='500px'\n",
    ")\n",
    "\n",
    "for _, row in df_coords.iterrows():\n",
    "    sp = row.get('species', '')\n",
    "    colour = species_colours.get(sp, '#888888')\n",
    "    safe_name = str(sp).replace(' ', '_') if sp else ''\n",
    "    gbif_link = 'https://www.gbif.org/occurrence/' + str(int(row['gbifID']))\n",
    "    year_str = str(int(row['year'])) if pd.notna(row.get('year')) else ''\n",
    "    inst_str = str(row.get('institutionCode', ''))\n",
    "    popup_html = (\n",
    "        '<b><i>' + str(sp) + '</i></b><br>' +\n",
    "        inst_str + ' ' + year_str + '<br>' +\n",
    "        '<a href=\"' + gbif_link + '\" target=\"_blank\">GBIF record</a>'\n",
    "    )\n",
    "    folium.CircleMarker(\n",
    "        location=[row['decimalLatitude'], row['decimalLongitude']],\n",
    "        radius=7,\n",
    "        color=colour,\n",
    "        fill=True,\n",
    "        fill_color=colour,\n",
    "        fill_opacity=0.85,\n",
    "        popup=folium.Popup(popup_html, max_width=220),\n",
    "        tooltip='<i>' + str(sp) + '</i>'\n",
    "    ).add_to(overview_map)\n",
    "\n",
    "# Species legend\n",
    "legend_items = ''.join(\n",
    "    '<span style=\"color:' + c + ';\">&#9679;</span> <i>' + sp + '</i><br>'\n",
    "    for sp, c in sorted(species_colours.items())\n",
    ")\n",
    "legend_html = (\n",
    "    '<div style=\"position:fixed; bottom:20px; left:20px; z-index:9999;'\n",
    "    ' background:white; padding:10px 14px; border-radius:6px;'\n",
    "    ' border:1px solid #ccc; font-size:11px; line-height:1.8;'\n",
    "    ' max-height:280px; overflow-y:auto;\">'\n",
    "    '<b>Species</b><br>' + legend_items + '</div>'\n",
    ")\n",
    "overview_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "overview_map.save('maps/montserrat_overview.html')\n",
    "print('Saved maps/montserrat_overview.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_toc.yml', 'r') as f:\n",
    "    toc = yaml.safe_load(f)\n",
    "\n",
    "# Update Part 2 (taxa) with sorted list\n",
    "toc_taxa_sorted = sorted(toc_taxa, key=lambda x: x['file'])\n",
    "toc['parts'][1]['chapters'] = toc_taxa_sorted\n",
    "\n",
    "# Also update Part 1 (organisation) from directory listing\n",
    "org_chapters = []\n",
    "for fname in sorted(os.listdir('organisation')):\n",
    "    if fname.endswith('.md'):\n",
    "        org_chapters.append({'file': f'organisation/{fname[:-3]}'})\n",
    "toc['parts'][0]['chapters'] = org_chapters\n",
    "\n",
    "with open('_toc.yml', 'w') as f:\n",
    "    yaml.dump(toc, f, allow_unicode=True, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print('_toc.yml updated.')\n",
    "print(f'  Part 1 (collections): {len(org_chapters)} chapters')\n",
    "print(f'  Part 2 (taxa):        {len(toc_taxa_sorted)} chapters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "All taxa pages have been generated. You can now build the Jupyter Book:\n",
    "\n",
    "```bash\n",
    "jupyter-book build .\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}